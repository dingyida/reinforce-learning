{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dingyida/reinforce-learning/blob/main/lab11_MBRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 11: Solving the mountaincar problem in 1 episode\n",
        "\n",
        "In this lab, you will use a Gaussian Process (GP) model to learn the dynamics of the Mountain Car system.\n",
        "Then, based on Lab 8, you will use MPPI or MPPI-Simplified to write the MPC loop that controls the vehicle.\n",
        "The goal is to solve the Mountain Car problem in one episode.\n",
        "\n",
        "## Provided code\n",
        "* The following code implements a Gaussian Process regression model that predicts the next-state change (Δx) given [position, velocity, action].\n",
        "* Example training data collected from random actions.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZaPgkgG-EeiF"
      },
      "id": "ZaPgkgG-EeiF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c2bf8d-67ba-417e-b37f-654874a4f93c",
      "metadata": {
        "id": "25c2bf8d-67ba-417e-b37f-654874a4f93c"
      },
      "outputs": [],
      "source": [
        "# %matplotlib widget\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpytorch"
      ],
      "metadata": {
        "id": "TIpZs-DJAfTU"
      },
      "id": "TIpZs-DJAfTU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7888831a-4d39-4dd7-91f1-53fabf49ebd4",
      "metadata": {
        "id": "7888831a-4d39-4dd7-91f1-53fabf49ebd4"
      },
      "source": [
        "# Gaussian Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b35003-8458-426b-a95f-87a8982d7d40",
      "metadata": {
        "id": "a5b35003-8458-426b-a95f-87a8982d7d40"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gpytorch\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================\n",
        "# ---- Base Exact GP model -------------------\n",
        "# ============================================================\n",
        "\n",
        "class ExactGPModel(gpytorch.models.ExactGP):\n",
        "    def __init__(self, train_x, train_y, likelihood, kernel='RBF', ard_dims=None):\n",
        "        super().__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean()\n",
        "\n",
        "        # Choose kernel type\n",
        "        if kernel == 'RBF':\n",
        "            base_kernel = gpytorch.kernels.RBFKernel(ard_num_dims=ard_dims)\n",
        "        elif kernel == 'Matern':\n",
        "            base_kernel = gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=ard_dims)\n",
        "        elif kernel == 'RQ':\n",
        "            base_kernel = gpytorch.kernels.RationalQuadraticKernel(ard_num_dims=ard_dims)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported kernel type: {kernel}\")\n",
        "\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ---- Individual GP Manager: handles data + normalization ----\n",
        "# ============================================================\n",
        "\n",
        "class GPManager:\n",
        "    def __init__(self, kernel='RBF', lr=0.03, iters=1000):\n",
        "        self.kernel = kernel\n",
        "        self.lr = lr\n",
        "        self.iters = iters\n",
        "        self.trained = False\n",
        "        self.X_train = []\n",
        "        self.Y_train = []\n",
        "\n",
        "        self.likelihood = None\n",
        "        self.model = None\n",
        "\n",
        "\n",
        "    # ----------------------------- #\n",
        "    #        FIT / INITIAL TRAIN    #\n",
        "    # ----------------------------- #\n",
        "    def fit(self, X, Y):\n",
        "        X = torch.tensor(X, dtype=torch.float32)\n",
        "        Y = torch.tensor(Y, dtype=torch.float32)\n",
        "\n",
        "        self.X_train = X.clone()\n",
        "        self.Y_train = Y.clone()\n",
        "\n",
        "        self.retrain()\n",
        "\n",
        "    def retrain(self):\n",
        "        # Normalize the input/output and then train the model\n",
        "        self._compute_normalization()\n",
        "        self._train_model()\n",
        "\n",
        "    # ----------------------------- #\n",
        "    #       ADD NEW DATA POINTS     #\n",
        "    # ----------------------------- #\n",
        "    def add_data(self, X_new, Y_new, retrain=True):\n",
        "        \"\"\"\n",
        "        Add new data (single or batch) to GP training set.\n",
        "        Optionally retrain the model.\n",
        "        \"\"\"\n",
        "        X_new = torch.tensor(X_new, dtype=torch.float32)\n",
        "        Y_new = torch.tensor(Y_new, dtype=torch.float32).flatten()  # ensure 1D\n",
        "\n",
        "        # Also flatten stored Y to ensure shape consistency\n",
        "        if self.Y_train.ndim > 1:\n",
        "            self.Y_train = self.Y_train.flatten()\n",
        "\n",
        "        # Append new data\n",
        "        self.X_train = torch.cat([self.X_train, X_new], dim=0)\n",
        "        self.Y_train = torch.cat([self.Y_train, Y_new], dim=0)\n",
        "\n",
        "        if retrain:\n",
        "            self.retrain()\n",
        "\n",
        "    # ----------------------------- #\n",
        "    #         INTERNAL UTILS        #\n",
        "    # ----------------------------- #\n",
        "    def _compute_normalization(self):\n",
        "        self.X_mean, self.X_std = self.X_train.mean(0), self.X_train.std(0)\n",
        "        self.Y_mean, self.Y_std = float(self.Y_train.mean(0)), float(self.Y_train.std(0))\n",
        "\n",
        "        Xn = (self.X_train - self.X_mean) / self.X_std\n",
        "        Yn = (self.Y_train - self.Y_mean) / self.Y_std\n",
        "\n",
        "        self.Xn, self.Yn = Xn, Yn\n",
        "\n",
        "    def dataset(self):\n",
        "        # Extract training data (already stored inside the wrapper)\n",
        "        X_train = self.X_train.numpy()\n",
        "        Y_train = self.Y_train.numpy()\n",
        "        return X_train, Y_train\n",
        "\n",
        "\n",
        "    def _train_model(self):\n",
        "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "        self.likelihood.noise_covar.initialize(noise=1e-3)\n",
        "        self.model = ExactGPModel(self.Xn, self.Yn, self.likelihood,\n",
        "                                  kernel=self.kernel, ard_dims=self.X_train.shape[-1])\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # Train the model\n",
        "        # -------------------------------------------------\n",
        "        self.train_gp(self.model, self.likelihood, self.Xn, self.Yn)\n",
        "        self.trained = True\n",
        "\n",
        "    def train_gp(self, model, likelihood, x, y):\n",
        "        model.train(); likelihood.train()\n",
        "        opt = torch.optim.Adam(model.parameters(), lr=self.lr)\n",
        "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "        for _ in range(self.iters):\n",
        "            opt.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = -mll(out, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        model.eval(); likelihood.eval()\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not self.trained:\n",
        "            raise RuntimeError(\"GP has not been trained yet.\")\n",
        "\n",
        "        # Normalize the input\n",
        "        X = torch.as_tensor(X, dtype=torch.float32)\n",
        "        Xn = (X - self.X_mean) / self.X_std\n",
        "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
        "            pred = self.likelihood(self.model(Xn))\n",
        "\n",
        "            # Unonormalize the output\n",
        "            mean = pred.mean.cpu().numpy() * self.Y_std + self.Y_mean\n",
        "            var = pred.variance.cpu().numpy() * (self.Y_std ** 2)\n",
        "        # Return the unnormalized output\n",
        "        return mean, var\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16944823-542c-4000-82ef-04ef0ffe0168",
      "metadata": {
        "id": "16944823-542c-4000-82ef-04ef0ffe0168"
      },
      "source": [
        "# Setup environment and collect initial data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71a19c88-76fb-4d42-996f-6605377fd68e",
      "metadata": {
        "id": "71a19c88-76fb-4d42-996f-6605377fd68e"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "# import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1.  Environment setup\n",
        "# --------------------------------------------------------------\n",
        "env = gym.make(\"MountainCarContinuous-v0\", max_episode_steps=500)\n",
        "n_state = env.observation_space.shape[0]    # [position, velocity]\n",
        "n_action = env.action_space.shape[0]        # 1 continuous action\n",
        "n_output = 2                                # Δpos, Δvel\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2.  Collect initial random data\n",
        "# --------------------------------------------------------------\n",
        "data = {'X': [], 'Y': []}\n",
        "\n",
        "obs, _ = env.reset(seed=0)\n",
        "for _ in range(200):  # collect 500 transitions\n",
        "    a = env.action_space.sample()  # random continuous action in [-1,1]\n",
        "    x_next, r, term, trunc, _ = env.step(a)\n",
        "    data['X'].append(np.concatenate([obs, a]))   # [pos, vel, action]\n",
        "    data['Y'].append(x_next - obs)               # Δstate\n",
        "    obs = x_next\n",
        "    if term or trunc:\n",
        "        obs, _ = env.reset()\n",
        "\n",
        "X = np.array(data['X'])[::3]\n",
        "Y = np.array(data['Y'])[::3]\n",
        "print(f\"Collected {len(X)} transitions.\")\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3.  Train GP dynamics models\n",
        "# --------------------------------------------------------------\n",
        "gps = [GPManager(kernel='RBF', iters=300) for _ in range(n_output)]\n",
        "\n",
        "for d in range(n_output):\n",
        "    gps[d].fit(X, Y[:, d])\n",
        "    print(f\"Trained GP for Δstate[{d}] with {len(X)} samples.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56725f5c-5e0f-4d1f-a655-df49f08d7fb6",
      "metadata": {
        "id": "56725f5c-5e0f-4d1f-a655-df49f08d7fb6"
      },
      "source": [
        "# Visualize collected data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b6b1dc-fe18-4e77-b43a-f44abeae90a3",
      "metadata": {
        "id": "43b6b1dc-fe18-4e77-b43a-f44abeae90a3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Visualization setup\n",
        "# --------------------------------------------------------\n",
        "gp = gps[1]   # GP for Δvelocity\n",
        "a_values = [-1.0, 0.0, 1.0]  # representative actions\n",
        "\n",
        "# Get raw training data\n",
        "X_train, Y_train = gp.dataset()\n",
        "pos, vel, act = X_train[:, 0], X_train[:, 1], X_train[:, 2]\n",
        "dvel = Y_train  # Δvelocity targets\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Define grid for visualization\n",
        "# --------------------------------------------------------\n",
        "p_min, p_max = pos.min(), pos.max()\n",
        "v_min, v_max = vel.min(), vel.max()\n",
        "\n",
        "p_grid = np.linspace(p_min, p_max, 60)\n",
        "v_grid = np.linspace(v_min, v_max, 60)\n",
        "P, V = np.meshgrid(p_grid, v_grid)\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Generate and plot for each action\n",
        "# --------------------------------------------------------\n",
        "for a_fixed in a_values:\n",
        "    print(f\"Plotting for action a={a_fixed}\")\n",
        "\n",
        "    # Predict using the GP for this action\n",
        "    X_grid = np.column_stack([P.ravel(), V.ravel(), np.full_like(P.ravel(), a_fixed)])\n",
        "    Mean, var = gp.predict(X_grid)\n",
        "    Mean = Mean.reshape(P.shape)\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # Plot as surface\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    surf = ax.plot_surface(P, V, Mean, cmap='coolwarm',\n",
        "                           linewidth=0, antialiased=True, alpha=0.9)\n",
        "\n",
        "    # Overlay training data close to this action value\n",
        "    mask = np.abs(act - a_fixed) < 0.5\n",
        "    print(f\"Values near action a={a_fixed} n={np.sum(mask)}\")\n",
        "    ax.scatter(pos[mask], vel[mask], dvel[mask],\n",
        "               color='k', s=15, alpha=0.7, label='data')\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # Labels and title\n",
        "    ax.set_xlabel('Position')\n",
        "    ax.set_ylabel('Velocity')\n",
        "    ax.set_zlabel('ΔVelocity')\n",
        "    ax.set_title(f\"Action = {a_fixed:.1f}: GP mean for Δvelocity\")\n",
        "\n",
        "    fig.colorbar(surf, ax=ax, shrink=0.6, aspect=10, label='GP mean')\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b1daefb-64c1-48a5-b636-5cabe510de6a",
      "metadata": {
        "id": "8b1daefb-64c1-48a5-b636-5cabe510de6a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Choose which GP to visualize\n",
        "# --------------------------------------------------------\n",
        "gp = gps[1]   # GP for Δvelocity (index 0 for Δposition)\n",
        "a_fixed = -1.0 # fixed continuous action (maximum thrust)\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Get training data\n",
        "# --------------------------------------------------------\n",
        "X_train, Y_train = gp.dataset()\n",
        "pos, vel, act = X_train[:, 0], X_train[:, 1], X_train[:, 2]\n",
        "dvel = Y_train\n",
        "\n",
        "# Select samples close to a=1 for overlay\n",
        "mask = np.abs(act - a_fixed) < 0.5\n",
        "print(f\"Values near action a={a_fixed} → n={np.sum(mask)}\")\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Define position–velocity grid\n",
        "# --------------------------------------------------------\n",
        "p_min, p_max = -1.2, 0.6\n",
        "v_min, v_max = -0.07, 0.07\n",
        "p_grid = np.linspace(p_min, p_max, 80)\n",
        "v_grid = np.linspace(v_min, v_max, 80)\n",
        "P, V = np.meshgrid(p_grid, v_grid)\n",
        "\n",
        "# Query points for the fixed action\n",
        "X_grid = np.column_stack([P.ravel(), V.ravel(), np.full_like(P.ravel(), a_fixed)])\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# GP predictions\n",
        "# --------------------------------------------------------\n",
        "Mean, Var = gp.predict(X_grid)\n",
        "Mean = Mean.reshape(P.shape)\n",
        "Std = np.sqrt(Var.reshape(P.shape))\n",
        "\n",
        "# Normalize Std for color mapping\n",
        "norm = plt.Normalize(vmin=Std.min(), vmax=Std.max())\n",
        "colors = plt.cm.viridis(norm(Std))\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Plot surface: Mean as height, Std as color\n",
        "# --------------------------------------------------------\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "surf = ax.plot_surface(\n",
        "    P, V, Mean,\n",
        "    facecolors=colors, linewidth=0, antialiased=False, shade=False\n",
        ")\n",
        "\n",
        "# Colorbar = predictive uncertainty\n",
        "m = plt.cm.ScalarMappable(cmap='viridis', norm=norm)\n",
        "m.set_array(Std)\n",
        "cbar = fig.colorbar(m, ax=ax, shrink=0.6, aspect=10)\n",
        "cbar.set_label('GP Predictive Std (uncertainty)')\n",
        "\n",
        "# Overlay raw data (samples with similar a)\n",
        "ax.scatter(\n",
        "    pos[mask], vel[mask], dvel[mask],\n",
        "    color='k', s=15, alpha=0.6, label='training data (a≈1)'\n",
        ")\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Labels and title\n",
        "# --------------------------------------------------------\n",
        "ax.set_xlabel('Position')\n",
        "ax.set_ylabel('Velocity')\n",
        "ax.set_zlabel('ΔVelocity')\n",
        "ax.set_title(\"GP Model for Action a=1.0 — Mean Surface (height), Std (color)\")\n",
        "ax.view_init(elev=30, azim=230)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b7ead1-701c-4fac-b6e5-ef00839ddc2d",
      "metadata": {
        "id": "43b7ead1-701c-4fac-b6e5-ef00839ddc2d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Choose GP: Δposition model\n",
        "# --------------------------------------------------------\n",
        "gp = gps[0]       # GP for Δposition\n",
        "v_fixed = 0.0     # fix velocity\n",
        "a_fixed = -1.0     # fix action\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Define position grid\n",
        "# --------------------------------------------------------\n",
        "p_min, p_max = -1.2, 0.6\n",
        "p_grid = np.linspace(p_min, p_max, 200)\n",
        "\n",
        "# Construct query points [p, v_fixed, a_fixed]\n",
        "X_query = np.column_stack([p_grid, np.full_like(p_grid, v_fixed), np.full_like(p_grid, a_fixed)])\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Predict GP mean and std\n",
        "# --------------------------------------------------------\n",
        "Mean, Var = gp.predict(X_query)\n",
        "Std = np.sqrt(Var)\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Plot mean ± std as shaded region\n",
        "# --------------------------------------------------------\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(p_grid, Mean, 'b-', lw=2, label='GP mean Δp')\n",
        "plt.fill_between(p_grid, Mean - 2*Std, Mean + 2*Std,\n",
        "                 color='blue', alpha=0.2, label='±2σ (uncertainty)')\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Overlay training data near v=0 and a=1\n",
        "# --------------------------------------------------------\n",
        "X_train, Y_train = gp.dataset()\n",
        "mask = (np.abs(X_train[:, 1] - v_fixed) < 0.01) & (np.abs(X_train[:, 2] - a_fixed) < 0.5)\n",
        "plt.scatter(X_train[mask, 0], Y_train[mask], color='k', s=25, alpha=0.7, label='training data (v≈0, a≈1)')\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Labels and title\n",
        "# --------------------------------------------------------\n",
        "plt.xlabel(\"Position p\")\n",
        "plt.ylabel(\"ΔPosition\")\n",
        "plt.title(f\"ΔPosition vs Position (v={v_fixed}, a={a_fixed})\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1\n",
        "Use the trained GP as a learned dynamics model to control the Mountain Car environment using Model Predictive Control (MPC).\n",
        "\n",
        "You can choose between:\n",
        "* MPPI (Model Predictive Path Integral) – probabilistic trajectory weighting, or\n",
        "* MPPI-Simplified (Random Shooting) – select the lowest-cost trajectory among random samples.\n",
        "\n",
        "Your controller should plan ahead, predict future states using the GP, and drive the car to reach the goal in a single episode.\n",
        "\n",
        "### Expected Outcome\n",
        "By the end of the exercise, your controller should:\n",
        "* Use the GP model to predict the system dynamics\n",
        "* Plan and select optimal actions using MPC\n",
        "* Drive the car to reach the goal in one episode\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "* Your implementation of the mpc_action() function\n",
        "* A plot showing the car’s position versus time\n",
        "* A short explanation (2–3 sentences) describing how MBRL is more efficient than Q-learning.\n",
        "* Describe the downside of MBRL over Q-learning"
      ],
      "metadata": {
        "id": "umw6G8zTFiYn"
      },
      "id": "umw6G8zTFiYn"
    },
    {
      "cell_type": "markdown",
      "id": "b4494e68-e3f6-47b4-a34b-c4ffc2fb832e",
      "metadata": {
        "id": "b4494e68-e3f6-47b4-a34b-c4ffc2fb832e"
      },
      "source": [
        "# MPC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adfa9b8f-efb8-41ea-89ec-f126d9417e7f",
      "metadata": {
        "id": "adfa9b8f-efb8-41ea-89ec-f126d9417e7f"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# GP + MPPI for MountainCarContinuous-v0 (Gymnasium+GPyTorch)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import gpytorch\n",
        "import matplotlib.pyplot as plt\n",
        "import gymnasium as gym\n",
        "\n",
        "# -----------------------------\n",
        "# Reproducibility\n",
        "# -----------------------------\n",
        "SEED = 0\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# -----------------------------\n",
        "# Environment\n",
        "# -----------------------------\n",
        "env = gym.make(\"MountainCarContinuous-v0\", max_episode_steps=500)\n",
        "\n",
        "POS_LOW, POS_HIGH = env.observation_space.low[0],  env.observation_space.high[0]\n",
        "VEL_LOW, VEL_HIGH = env.observation_space.low[1],  env.observation_space.high[1]\n",
        "ACT_LOW, ACT_HIGH = env.action_space.low[0],       env.action_space.high[0]\n",
        "\n",
        "# ============================================================\n",
        "# 1) GPyTorch GP model + Manager\n",
        "# ============================================================\n",
        "\n",
        "class ExactGPModel(gpytorch.models.ExactGP):\n",
        "    def __init__(self, train_x, train_y, likelihood, kernel='RBF', ard_dims=None):\n",
        "        super().__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean()\n",
        "\n",
        "        if kernel == 'RBF':\n",
        "            base_kernel = gpytorch.kernels.RBFKernel(ard_num_dims=ard_dims)\n",
        "        elif kernel == 'Matern':\n",
        "            base_kernel = gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=ard_dims)\n",
        "        elif kernel == 'RQ':\n",
        "            base_kernel = gpytorch.kernels.RationalQuadraticKernel(ard_num_dims=ard_dims)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported kernel type: {kernel}\")\n",
        "\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "\n",
        "class GPManager:\n",
        "    \"\"\"\n",
        "    Wraps an ExactGP for 1D target (single output).\n",
        "    Handles normalization, training, prediction, and incremental data.\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel='RBF', lr=0.03, iters=600):\n",
        "        self.kernel = kernel\n",
        "        self.lr = lr\n",
        "        self.iters = iters\n",
        "        self.trained = False\n",
        "\n",
        "        self.X_train = None\n",
        "        self.Y_train = None\n",
        "\n",
        "        self.X_mean = None\n",
        "        self.X_std  = None\n",
        "        self.Y_mean = None\n",
        "        self.Y_std  = None\n",
        "\n",
        "        self.likelihood = None\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        X = torch.tensor(X, dtype=torch.float32)\n",
        "        Y = torch.tensor(Y, dtype=torch.float32).flatten()\n",
        "\n",
        "        self.X_train = X.clone()\n",
        "        self.Y_train = Y.clone()\n",
        "\n",
        "        self._compute_normalization()\n",
        "        self._train_model()\n",
        "        self.trained = True\n",
        "\n",
        "    def add_data(self, X_new, Y_new, retrain=True):\n",
        "        X_new = torch.tensor(X_new, dtype=torch.float32)\n",
        "        Y_new = torch.tensor(Y_new, dtype=torch.float32).flatten()\n",
        "\n",
        "        if self.X_train is None:\n",
        "            self.X_train = X_new\n",
        "            self.Y_train = Y_new\n",
        "        else:\n",
        "            self.X_train = torch.cat([self.X_train, X_new], dim=0)\n",
        "            self.Y_train = torch.cat([self.Y_train, Y_new], dim=0)\n",
        "\n",
        "        if retrain:\n",
        "            self._compute_normalization()\n",
        "            self._train_model()\n",
        "            self.trained = True\n",
        "\n",
        "    def _compute_normalization(self, eps=1e-8):\n",
        "        X = self.X_train\n",
        "        Y = self.Y_train\n",
        "\n",
        "        X_mean = X.mean(dim=0)\n",
        "        X_std  = X.std(dim=0)\n",
        "        X_std  = torch.clamp(X_std, min=eps)\n",
        "\n",
        "        Y_mean = float(Y.mean(dim=0))\n",
        "        Y_std  = float(Y.std(dim=0))\n",
        "        if Y_std < eps:\n",
        "            Y_std = 1.0  # avoid divide-by-zero; degenerate target not expected here\n",
        "\n",
        "        self.X_mean, self.X_std = X_mean, X_std\n",
        "        self.Y_mean, self.Y_std = Y_mean, Y_std\n",
        "\n",
        "        self.Xn = (X - X_mean) / X_std\n",
        "        self.Yn = (Y - Y_mean) / Y_std\n",
        "\n",
        "    def _train_model(self):\n",
        "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "        # small initial noise; GP will learn it\n",
        "        self.likelihood.noise_covar.initialize(noise=1e-3)\n",
        "\n",
        "        self.model = ExactGPModel(\n",
        "            self.Xn, self.Yn, self.likelihood,\n",
        "            kernel=self.kernel,\n",
        "            ard_dims=self.X_train.shape[-1]\n",
        "        )\n",
        "\n",
        "        self.model.train()\n",
        "        self.likelihood.train()\n",
        "\n",
        "        opt = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
        "\n",
        "        for _ in range(self.iters):\n",
        "            opt.zero_grad()\n",
        "            out = self.model(self.Xn)\n",
        "            loss = -mll(out, self.Yn)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        self.model.eval()\n",
        "        self.likelihood.eval()\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not self.trained:\n",
        "            raise RuntimeError(\"GP has not been trained yet.\")\n",
        "\n",
        "        X = torch.as_tensor(X, dtype=torch.float32)\n",
        "        Xn = (X - self.X_mean) / self.X_std\n",
        "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
        "            pred = self.likelihood(self.model(Xn))\n",
        "            mean = pred.mean.cpu().numpy() * self.Y_std + self.Y_mean\n",
        "            var  = pred.variance.cpu().numpy() * (self.Y_std ** 2)\n",
        "        return mean, var\n",
        "\n",
        "    def dataset(self):\n",
        "        return self.X_train.numpy(), self.Y_train.numpy()\n",
        "\n",
        "# ============================================================\n",
        "# 2) Collect random dataset from environment\n",
        "# ============================================================\n",
        "\n",
        "def collect_random_transitions(env, n_steps=200, ds_every=3, seed=SEED):\n",
        "    data_X, data_Y = [], []\n",
        "    obs, _ = env.reset(seed=seed)\n",
        "\n",
        "    for _ in range(n_steps):\n",
        "        a = env.action_space.sample()\n",
        "        x_next, r, term, trunc, _ = env.step(a)\n",
        "        data_X.append(np.concatenate([obs, a]))  # [pos, vel, act]\n",
        "        data_Y.append(x_next - obs)              # [Δpos, Δvel]\n",
        "        obs = x_next\n",
        "        if term or trunc:\n",
        "            obs, _ = env.reset()\n",
        "\n",
        "    X = np.array(data_X)[::ds_every]\n",
        "    Y = np.array(data_Y)[::ds_every]\n",
        "    return X, Y\n",
        "\n",
        "print(\"Collecting data...\")\n",
        "X, Y = collect_random_transitions(env, n_steps=300, ds_every=2, seed=SEED)\n",
        "print(f\"Collected {len(X)} samples. X shape={X.shape}, Y shape={Y.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3) Train two GPs: Δpos and Δvel\n",
        "# ============================================================\n",
        "\n",
        "gps = [GPManager(kernel='RBF', lr=0.03, iters=600) for _ in range(2)]\n",
        "gps[0].fit(X, Y[:, 0])  # Δposition\n",
        "gps[1].fit(X, Y[:, 1])  # Δvelocity\n",
        "print(\"Trained GP[0] (Δpos) and GP[1] (Δvel).\")\n",
        "\n",
        "# ============================================================\n",
        "# 4) GP-based dynamics + cost\n",
        "# ============================================================\n",
        "\n",
        "def predict_delta_with_gps(gps, X_batch):\n",
        "    m0, v0 = gps[0].predict(X_batch)  # Δpos\n",
        "    m1, v1 = gps[1].predict(X_batch)  # Δvel\n",
        "    d_mean = np.stack([m0, m1], axis=-1)\n",
        "    d_var  = np.stack([v0, v1], axis=-1)\n",
        "    return d_mean, d_var\n",
        "\n",
        "def mountain_car_dynamics_gp(x, v, a, gps):\n",
        "    a = float(np.clip(a, ACT_LOW, ACT_HIGH))\n",
        "    X = np.array([[x, v, a]], dtype=np.float32)\n",
        "    d_mean, _ = predict_delta_with_gps(gps, X)\n",
        "\n",
        "    x_next = x + float(d_mean[0, 0])\n",
        "    v_next = v + float(d_mean[0, 1])\n",
        "\n",
        "    x_next = np.clip(x_next, POS_LOW, POS_HIGH)\n",
        "    v_next = np.clip(v_next, VEL_LOW, VEL_HIGH)\n",
        "    return np.array([x_next, v_next], dtype=np.float32)\n",
        "\n",
        "def potential_energy(p):\n",
        "    # matches MountainCar shape\n",
        "    return (0.0025 / 3.0) * np.sin(3.0 * p)\n",
        "\n",
        "def kinetic_energy(v):\n",
        "    return 0.5 * v**2\n",
        "\n",
        "def cost_fn(state, a, goal=0.5, eps=1e-3):\n",
        "    \"\"\"\n",
        "    Stable version of your cost:\n",
        "      - pos_error uses |x-goal| with epsilon to avoid division-by-zero\n",
        "      - energy tracking + action penalty\n",
        "    \"\"\"\n",
        "    x, v = state\n",
        "    pos_error = 1.0 / (np.abs(x - goal) + eps)\n",
        "\n",
        "    E      = 1000 * kinetic_energy(v) + 1000 * potential_energy(x)\n",
        "    E_goal = 1000 * kinetic_energy(0.0) + 1000 * potential_energy(goal)\n",
        "    energy_error = (E - E_goal) ** 2\n",
        "    energy_cost  = float(a) ** 2\n",
        "    return - E\n",
        "\n",
        "# ============================================================\n",
        "# 5) Rollouts and MPPI\n",
        "# ============================================================\n",
        "\n",
        "def roll_out_trajectory(s0, Ui, gamma=1.0, gps=None, beta_var=0.0):\n",
        "    \"\"\"\n",
        "    Rollout using learned GP dynamics.\n",
        "    s0: (2,) initial state\n",
        "    Ui: (H,) action sequence\n",
        "    gamma: discount factor\n",
        "    gps: [GP(Δpos), GP(Δvel)]\n",
        "    beta_var: risk weight on predictive variance (optional)\n",
        "    \"\"\"\n",
        "    assert gps is not None, \"Pass the trained gps=[gp_pos, gp_vel].\"\n",
        "\n",
        "    s = np.asarray(s0, dtype=np.float32).copy()\n",
        "    traj = [s.copy()]\n",
        "    H = len(Ui)\n",
        "    discount = 1.0\n",
        "    total_cost = 0.0\n",
        "\n",
        "    for k in range(H):\n",
        "        a = float(np.clip(Ui[k], ACT_LOW, ACT_HIGH))\n",
        "\n",
        "        X = np.array([[s[0], s[1], a]], dtype=np.float32)\n",
        "        d_mean, d_var = predict_delta_with_gps(gps, X)\n",
        "\n",
        "        s = np.array([s[0] + d_mean[0, 0], s[1] + d_mean[0, 1]], dtype=np.float32)\n",
        "        s[0] = np.clip(s[0], POS_LOW, POS_HIGH)\n",
        "        s[1] = np.clip(s[1], VEL_LOW, VEL_HIGH)\n",
        "        traj.append(s.copy())\n",
        "\n",
        "        J_step = cost_fn(s, a)\n",
        "        if beta_var > 0.0:\n",
        "            J_step += beta_var * float(d_var.sum())\n",
        "        total_cost += discount * J_step\n",
        "        discount *= gamma\n",
        "\n",
        "    return np.array(traj), total_cost\n",
        "\n",
        "\n",
        "def plot_trajectories(state, best_traj):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i, traj in enumerate(best_traj):\n",
        "        plt.plot(traj[:, 0], traj[:, 1], lw=2, alpha=0.9, label=f\"Traj {i+1}\")\n",
        "    plt.scatter(state[0], state[1], color='red', s=60, label=\"Start\", zorder=5)\n",
        "    plt.axvline(0.5, color='gray', ls='--', label='Goal position')\n",
        "    plt.xlabel(\"Position\")\n",
        "    plt.ylabel(\"Velocity\")\n",
        "    plt.title(\"Predicted Trajectories (GP Dynamics)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_trajectory(trajectory):\n",
        "    positions, velocities, actions = [], [], []\n",
        "    for obs, a in trajectory:\n",
        "        positions.append(obs[0]); velocities.append(obs[1]); actions.append(float(a))\n",
        "    positions = np.array(positions); velocities = np.array(velocities); actions = np.array(actions)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sc = plt.scatter(positions, velocities, c=actions, cmap='coolwarm', s=50, edgecolor='k', alpha=0.85)\n",
        "    plt.colorbar(sc, label=\"Action (acceleration)\")\n",
        "    plt.xlabel(\"Position\"); plt.ylabel(\"Velocity\")\n",
        "    plt.title(\"MountainCar — Executed Trajectory (colored by action)\")\n",
        "    plt.grid(True); plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "class MPPIController:\n",
        "    \"\"\"\n",
        "    Model Predictive Path Integral Controller with persistent action sequence.\n",
        "    Uses MPPI weighting to update the mean sequence; warm-start between steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, gps, H=80, N_seq=200, λ=0.2, σ=0.7, beta_var=0.0):\n",
        "        self.gps = gps\n",
        "        self.H = H\n",
        "        self.N_seq = N_seq\n",
        "        self.λ = λ\n",
        "        self.σ = σ\n",
        "        self.beta_var = beta_var\n",
        "        self.U_mean = np.zeros(H, dtype=np.float32)\n",
        "\n",
        "    def action(self, state, plot=False, plot_best=3):\n",
        "        H, N_seq, σ, λ = self.H, self.N_seq, self.σ, self.λ\n",
        "\n",
        "        # 0) warm start / shift sequence\n",
        "        self.U_mean = np.roll(self.U_mean, -1)\n",
        "        self.U_mean[-1] = 0.0\n",
        "\n",
        "        # 1) sample candidate sequences\n",
        "        noise = np.random.normal(0.0, σ, size=(N_seq, H)).astype(np.float32)\n",
        "        U = np.clip(self.U_mean[None, :] + noise, ACT_LOW, ACT_HIGH)\n",
        "\n",
        "        # 2) evaluate candidates with GP dynamics\n",
        "        J = np.zeros(N_seq, dtype=np.float64)\n",
        "        all_traj = []\n",
        "        for i in range(N_seq):\n",
        "            traj, total_cost = roll_out_trajectory(\n",
        "                s0=state, Ui=U[i], gamma=1.0, gps=self.gps, beta_var=self.beta_var\n",
        "            )\n",
        "            all_traj.append(traj)\n",
        "            J[i] = total_cost\n",
        "\n",
        "        # 3) MPPI weights (stable softmax)\n",
        "        J_min = np.min(J)\n",
        "        logits = -(J - J_min) / max(1e-8, λ)\n",
        "        w = np.exp(logits)\n",
        "        w /= np.sum(w)\n",
        "\n",
        "        # 4) update mean sequence with weighted noise (perturbations)\n",
        "        dU = w @ noise  # (H,)\n",
        "        self.U_mean = np.clip(self.U_mean + dU, ACT_LOW, ACT_HIGH)\n",
        "\n",
        "        if plot:\n",
        "            best_idx = np.argsort(J)[:plot_best]\n",
        "            best_traj = [all_traj[i] for i in best_idx]\n",
        "            plot_trajectories(state, best_traj)\n",
        "\n",
        "        return float(self.U_mean[0])\n",
        "\n",
        "# ============================================================\n",
        "# 6) Quick unit run: test rollout + MPPI closed loop\n",
        "# ============================================================\n",
        "\n",
        "# Test a single short rollout call (make sure gps is passed)\n",
        "Ui_test = np.zeros(5, dtype=np.float32)\n",
        "traj_test, J_test = roll_out_trajectory(np.array([-0.5, 0.0], dtype=np.float32), Ui_test, gps=gps)\n",
        "print(f\"Sanity test — rollout length={len(traj_test)}, cost={J_test:.3f}\")\n",
        "\n",
        "# MPPI closed-loop control with learned dynamics\n",
        "mppi = MPPIController(gps=gps, H=100, N_seq=60, λ=0.10, σ=0.7, beta_var=0.0)\n",
        "\n",
        "obs, _ = env.reset(seed=SEED)\n",
        "traj_exec = []\n",
        "for t in range(300):\n",
        "    a = mppi.action(obs, plot=(t == 0), plot_best=3)  # plot only at first step (optional)\n",
        "    traj_exec.append([obs.copy(), a])\n",
        "\n",
        "    obs, r, term, trunc, _ = env.step([a])  # env step for evaluation/logging\n",
        "    if (t % 1) == 0:\n",
        "        print(f\"t={t:3d}  obs={obs}  a={a:+.3f}\")\n",
        "    if term or trunc:\n",
        "        break\n",
        "\n",
        "print(f\"Total time: {t+1} step(s)\")\n",
        "plot_trajectory(traj_exec)\n",
        "\n",
        "# Energy proxy\n",
        "print(\"Energy:\", sum(a**2 for s, a in traj_exec))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Exercise 2 (Graduate students)\n",
        "Extend the MPC controller from Exercise 1 by incorporating Gaussian Process (GP) uncertainty into the MPPI algorithm.\n",
        "The goal is to study how including the GP’s predictive variance affects control performance and sample efficiency.\n",
        "\n",
        "\n",
        "* Include GP uncertainty (variance) in the MPPI algorithm.\n",
        "Modify the cost function or trajectory weighting so that trajectories passing through regions of high model uncertainty are penalized.\n",
        "\n",
        "* Compare two systems:\n",
        "  * MPPI using only the GP mean prediction (deterministic model).\n",
        "  * MPPI using both the GP mean and variance (uncertainty-aware model).\n",
        "* Evaluate and discuss the results:\n",
        "  * The MBRL system from Exercise 1 usually solves the Mountain Car problem in more than 100 steps, even after several episodes.\n",
        "  * Investigate whether incorporating uncertainty can help the controller reach the goal faster or with fewer samples.\n",
        "  * Provide plots of position over time for both cases.\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "* Your modified MPPI implementation that includes GP variance.\n",
        "* Two plots comparing:\n",
        "    * Position vs. time (with and without variance)\n",
        "    * Cumulative reward or number of steps to reach the goal\n",
        "* A short discussion (2–3 paragraphs) explaining how including uncertainty affects performance and why it might lead to better results."
      ],
      "metadata": {
        "id": "YbBTtVyeH2g7"
      },
      "id": "YbBTtVyeH2g7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# GP Uncertainty-Aware MPPI for MountainCarContinuous-v0\n",
        "# (Gymnasium + GPyTorch)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import gpytorch\n",
        "import matplotlib.pyplot as plt\n",
        "import gymnasium as gym\n",
        "\n",
        "# -----------------------------\n",
        "# Reproducibility\n",
        "# -----------------------------\n",
        "SEED = 0\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# -----------------------------\n",
        "# Environment\n",
        "# -----------------------------\n",
        "env = gym.make(\"MountainCarContinuous-v0\", max_episode_steps=500)\n",
        "\n",
        "POS_LOW, POS_HIGH = env.observation_space.low[0],  env.observation_space.high[0]\n",
        "VEL_LOW, VEL_HIGH = env.observation_space.low[1],  env.observation_space.high[1]\n",
        "ACT_LOW, ACT_HIGH = env.action_space.low[0],       env.action_space.high[0]\n",
        "\n",
        "# ============================================================\n",
        "# 1) GPyTorch GP model + Manager\n",
        "# ============================================================\n",
        "\n",
        "class ExactGPModel(gpytorch.models.ExactGP):\n",
        "    def __init__(self, train_x, train_y, likelihood, kernel='RBF', ard_dims=None):\n",
        "        super().__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean()\n",
        "\n",
        "        if kernel == 'RBF':\n",
        "            base_kernel = gpytorch.kernels.RBFKernel(ard_num_dims=ard_dims)\n",
        "        elif kernel == 'Matern':\n",
        "            base_kernel = gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=ard_dims)\n",
        "        elif kernel == 'RQ':\n",
        "            base_kernel = gpytorch.kernels.RationalQuadraticKernel(ard_num_dims=ard_dims)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported kernel type: {kernel}\")\n",
        "\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "\n",
        "class GPManager:\n",
        "    \"\"\"\n",
        "    Wraps an ExactGP for 1D target (single output).\n",
        "    Handles normalization, training, prediction, and incremental data.\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel='RBF', lr=0.03, iters=600):\n",
        "        self.kernel = kernel\n",
        "        self.lr = lr\n",
        "        self.iters = iters\n",
        "        self.trained = False\n",
        "\n",
        "        self.X_train = None\n",
        "        self.Y_train = None\n",
        "\n",
        "        self.X_mean = None\n",
        "        self.X_std  = None\n",
        "        self.Y_mean = None\n",
        "        self.Y_std  = None\n",
        "\n",
        "        self.likelihood = None\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        X = torch.tensor(X, dtype=torch.float32)\n",
        "        Y = torch.tensor(Y, dtype=torch.float32).flatten()\n",
        "\n",
        "        self.X_train = X.clone()\n",
        "        self.Y_train = Y.clone()\n",
        "\n",
        "        self._compute_normalization()\n",
        "        self._train_model()\n",
        "        self.trained = True\n",
        "\n",
        "    def add_data(self, X_new, Y_new, retrain=True):\n",
        "        X_new = torch.tensor(X_new, dtype=torch.float32)\n",
        "        Y_new = torch.tensor(Y_new, dtype=torch.float32).flatten()\n",
        "\n",
        "        if self.X_train is None:\n",
        "            self.X_train = X_new\n",
        "            self.Y_train = Y_new\n",
        "        else:\n",
        "            self.X_train = torch.cat([self.X_train, X_new], dim=0)\n",
        "            self.Y_train = torch.cat([self.Y_train, Y_new], dim=0)\n",
        "\n",
        "        if retrain:\n",
        "            self._compute_normalization()\n",
        "            self._train_model()\n",
        "            self.trained = True\n",
        "\n",
        "    def _compute_normalization(self, eps=1e-8):\n",
        "        X = self.X_train\n",
        "        Y = self.Y_train\n",
        "\n",
        "        X_mean = X.mean(dim=0)\n",
        "        X_std  = X.std(dim=0)\n",
        "        X_std  = torch.clamp(X_std, min=eps)\n",
        "\n",
        "        Y_mean = float(Y.mean(dim=0))\n",
        "        Y_std  = float(Y.std(dim=0))\n",
        "        if Y_std < eps:\n",
        "            Y_std = 1.0  # avoid divide-by-zero; degenerate target not expected here\n",
        "\n",
        "        self.X_mean, self.X_std = X_mean, X_std\n",
        "        self.Y_mean, self.Y_std = Y_mean, Y_std\n",
        "\n",
        "        self.Xn = (X - X_mean) / X_std\n",
        "        self.Yn = (Y - Y_mean) / Y_std\n",
        "\n",
        "    def _train_model(self):\n",
        "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "        # small initial noise; GP will learn it\n",
        "        self.likelihood.noise_covar.initialize(noise=1e-3)\n",
        "\n",
        "        self.model = ExactGPModel(\n",
        "            self.Xn, self.Yn, self.likelihood,\n",
        "            kernel=self.kernel,\n",
        "            ard_dims=self.X_train.shape[-1]\n",
        "        )\n",
        "\n",
        "        self.model.train()\n",
        "        self.likelihood.train()\n",
        "\n",
        "        opt = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
        "\n",
        "        for _ in range(self.iters):\n",
        "            opt.zero_grad()\n",
        "            out = self.model(self.Xn)\n",
        "            loss = -mll(out, self.Yn)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        self.model.eval()\n",
        "        self.likelihood.eval()\n",
        "\n",
        "    def predict(self, X, include_obs_noise: bool = False):\n",
        "        \"\"\"\n",
        "        Returns mean, variance in original (unnormalized) units.\n",
        "\n",
        "        include_obs_noise=False  -> epistemic/model uncertainty (preferred for risk-sensitive control)\n",
        "        include_obs_noise=True   -> predictive variance (epistemic + learned noise)\n",
        "        \"\"\"\n",
        "        if not self.trained:\n",
        "            raise RuntimeError(\"GP has not been trained yet.\")\n",
        "\n",
        "        X = torch.as_tensor(X, dtype=torch.float32)\n",
        "        Xn = (X - self.X_mean) / self.X_std\n",
        "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
        "            if include_obs_noise:\n",
        "                pred = self.likelihood(self.model(Xn))   # predictive: epistemic + noise\n",
        "            else:\n",
        "                pred = self.model(Xn)                    # epistemic only\n",
        "\n",
        "            mean = pred.mean.cpu().numpy() * self.Y_std + self.Y_mean\n",
        "            var  = pred.variance.cpu().numpy() * (self.Y_std ** 2)\n",
        "        return mean, var\n",
        "\n",
        "    def dataset(self):\n",
        "        return self.X_train.numpy(), self.Y_train.numpy()\n",
        "\n",
        "# ============================================================\n",
        "# 2) Collect random dataset from environment\n",
        "# ============================================================\n",
        "\n",
        "def collect_random_transitions(env, n_steps=200, ds_every=3, seed=SEED):\n",
        "    data_X, data_Y = [], []\n",
        "    obs, _ = env.reset(seed=seed)\n",
        "\n",
        "    for _ in range(n_steps):\n",
        "        a = env.action_space.sample()\n",
        "        x_next, r, term, trunc, _ = env.step(a)\n",
        "        data_X.append(np.concatenate([obs, a]))  # [pos, vel, act]\n",
        "        data_Y.append(x_next - obs)              # [Δpos, Δvel]\n",
        "        obs = x_next\n",
        "        if term or trunc:\n",
        "            obs, _ = env.reset()\n",
        "\n",
        "    X = np.array(data_X)[::ds_every]\n",
        "    Y = np.array(data_Y)[::ds_every]\n",
        "    return X, Y\n",
        "\n",
        "print(\"Collecting data...\")\n",
        "X, Y = collect_random_transitions(env, n_steps=300, ds_every=2, seed=SEED)\n",
        "print(f\"Collected {len(X)} samples. X shape={X.shape}, Y shape={Y.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3) Train two GPs: Δpos and Δvel\n",
        "# ============================================================\n",
        "\n",
        "gps = [GPManager(kernel='RBF', lr=0.03, iters=600) for _ in range(2)]\n",
        "gps[0].fit(X, Y[:, 0])  # Δposition\n",
        "gps[1].fit(X, Y[:, 1])  # Δvelocity\n",
        "print(\"Trained GP[0] (Δpos) and GP[1] (Δvel).\")\n",
        "\n",
        "# ============================================================\n",
        "# 4) GP-based dynamics + uncertainty-aware cost\n",
        "# ============================================================\n",
        "\n",
        "def predict_delta_with_gps(gps, X_batch, include_obs_noise=False):\n",
        "    m0, v0 = gps[0].predict(X_batch, include_obs_noise=include_obs_noise)  # Δpos\n",
        "    m1, v1 = gps[1].predict(X_batch, include_obs_noise=include_obs_noise)  # Δvel\n",
        "    d_mean = np.stack([m0, m1], axis=-1)\n",
        "    d_var  = np.stack([v0, v1], axis=-1)\n",
        "    return d_mean, d_var\n",
        "\n",
        "def mountain_car_dynamics_gp(x, v, a, gps, include_obs_noise=False):\n",
        "    a = float(np.clip(a, ACT_LOW, ACT_HIGH))\n",
        "    X = np.array([[x, v, a]], dtype=np.float32)\n",
        "    d_mean, _ = predict_delta_with_gps(gps, X, include_obs_noise=include_obs_noise)\n",
        "\n",
        "    x_next = x + float(d_mean[0, 0])\n",
        "    v_next = v + float(d_mean[0, 1])\n",
        "\n",
        "    x_next = np.clip(x_next, POS_LOW, POS_HIGH)\n",
        "    v_next = np.clip(v_next, VEL_LOW, VEL_HIGH)\n",
        "    return np.array([x_next, v_next], dtype=np.float32)\n",
        "\n",
        "def cost_fn(state, a, d_var=None, goal=0.5, w=None):\n",
        "    \"\"\"\n",
        "    Uncertainty-aware stage cost.\n",
        "\n",
        "    state  : [x, v]\n",
        "    a      : scalar action\n",
        "    d_var  : [var(Δpos), var(Δvel)] from the GP (same scale as state deltas)\n",
        "    goal   : target position\n",
        "    w      : dict of weights\n",
        "            w = {\n",
        "                \"pos\":  5.0,     # position tracking (quadratic)\n",
        "                \"vel\":  0.5,     # velocity damping\n",
        "                \"act\":  1e-3,    # control effort\n",
        "                \"beta\": 0.0,     # global risk weight (>=0)\n",
        "                \"var_pos\": 1.0,  # per-dim variance weights\n",
        "                \"var_vel\": 0.1,\n",
        "            }\n",
        "    \"\"\"\n",
        "    if w is None:\n",
        "        w = {\"pos\": 5.0, \"vel\": 0.5, \"act\": 1e-3,\n",
        "             \"beta\": 0.0, \"var_pos\": 1.0, \"var_vel\": 0.1}\n",
        "\n",
        "    x, v = state\n",
        "    # task costs\n",
        "    pos_cost = (x - goal) ** 2\n",
        "    vel_cost = v ** 2\n",
        "    act_cost = float(a) ** 2\n",
        "\n",
        "    # uncertainty penalty (risk-sensitive term)\n",
        "    var_cost = 0.0\n",
        "    if d_var is not None:\n",
        "        var_cost = w[\"var_pos\"] * float(d_var[0]) + w[\"var_vel\"] * float(d_var[1])\n",
        "\n",
        "    return w[\"pos\"] * pos_cost + w[\"vel\"] * vel_cost + w[\"act\"] * act_cost + w[\"beta\"] * var_cost\n",
        "\n",
        "# ============================================================\n",
        "# 5) Rollouts and MPPI\n",
        "# ============================================================\n",
        "\n",
        "def roll_out_trajectory(s0, Ui, gamma=1.0, gps=None, beta_var=0.0, include_obs_noise=False, w_cost=None):\n",
        "    \"\"\"\n",
        "    Rollout using learned GP dynamics with uncertainty-aware cost.\n",
        "    s0: (2,) initial state\n",
        "    Ui: (H,) action sequence\n",
        "    gamma: discount factor\n",
        "    gps: [GP(Δpos), GP(Δvel)]\n",
        "    beta_var: risk weight -> forwarded into cost_fn as w['beta']\n",
        "    include_obs_noise: False -> epistemic-only variance; True -> predictive variance.\n",
        "    w_cost: optional dict of cost weights\n",
        "    \"\"\"\n",
        "    assert gps is not None, \"Pass the trained gps=[gp_pos, gp_vel].\"\n",
        "\n",
        "    if w_cost is None:\n",
        "        w_cost = {\"pos\": 5.0, \"vel\": 0.5, \"act\": 1e-3, \"beta\": beta_var, \"var_pos\": 1.0, \"var_vel\": 0.1}\n",
        "\n",
        "    s = np.asarray(s0, dtype=np.float32).copy()\n",
        "    traj = [s.copy()]\n",
        "    H = len(Ui)\n",
        "    discount = 1.0\n",
        "    total_cost = 0.0\n",
        "\n",
        "    for k in range(H):\n",
        "        a = float(np.clip(Ui[k], ACT_LOW, ACT_HIGH))\n",
        "\n",
        "        X = np.array([[s[0], s[1], a]], dtype=np.float32)\n",
        "        d_mean, d_var = predict_delta_with_gps(gps, X, include_obs_noise=include_obs_noise)\n",
        "\n",
        "        # update state with GP mean\n",
        "        s = np.array([s[0] + d_mean[0, 0], s[1] + d_mean[0, 1]], dtype=np.float32)\n",
        "        s[0] = np.clip(s[0], POS_LOW, POS_HIGH)\n",
        "        s[1] = np.clip(s[1], VEL_LOW, VEL_HIGH)\n",
        "        traj.append(s.copy())\n",
        "\n",
        "        # uncertainty-aware stage cost\n",
        "        J_step = cost_fn(s, a, d_var=d_var[0], w=w_cost)\n",
        "        total_cost += discount * J_step\n",
        "        discount *= gamma\n",
        "\n",
        "    return np.array(traj), total_cost\n",
        "\n",
        "\n",
        "def plot_trajectories(state, best_traj):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i, traj in enumerate(best_traj):\n",
        "        plt.plot(traj[:, 0], traj[:, 1], lw=2, alpha=0.9, label=f\"Traj {i+1}\")\n",
        "    plt.scatter(state[0], state[1], color='red', s=60, label=\"Start\", zorder=5)\n",
        "    plt.axvline(0.5, color='gray', ls='--', label='Goal position')\n",
        "    plt.xlabel(\"Position\")\n",
        "    plt.ylabel(\"Velocity\")\n",
        "    plt.title(\"Predicted Trajectories (GP Dynamics)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_trajectory(trajectory):\n",
        "    positions, velocities, actions = [], [], []\n",
        "    for obs, a in trajectory:\n",
        "        positions.append(obs[0]); velocities.append(obs[1]); actions.append(float(a))\n",
        "    positions = np.array(positions); velocities = np.array(velocities); actions = np.array(actions)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sc = plt.scatter(positions, velocities, c=actions, cmap='coolwarm', s=50, edgecolor='k', alpha=0.85)\n",
        "    plt.colorbar(sc, label=\"Action (acceleration)\")\n",
        "    plt.xlabel(\"Position\"); plt.ylabel(\"Velocity\")\n",
        "    plt.title(\"MountainCar — Executed Trajectory (colored by action)\")\n",
        "    plt.grid(True); plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "class MPPIController:\n",
        "    \"\"\"\n",
        "    Model Predictive Path Integral Controller with persistent action sequence.\n",
        "    Uses MPPI weighting to update the mean sequence; warm-start between steps.\n",
        "\n",
        "    beta_var: global risk knob -> forwarded to stage cost; larger makes controller avoid uncertain regions.\n",
        "    include_obs_noise: False -> penalize epistemic-only (model) uncertainty; True -> penalize predictive (model+noise).\n",
        "    \"\"\"\n",
        "    def __init__(self, gps, H=80, N_seq=200, λ=0.2, σ=0.7, beta_var=0.0, include_obs_noise=False, w_cost=None):\n",
        "        self.gps = gps\n",
        "        self.H = H\n",
        "        self.N_seq = N_seq\n",
        "        self.λ = λ\n",
        "        self.σ = σ\n",
        "        self.beta_var = beta_var\n",
        "        self.include_obs_noise = include_obs_noise\n",
        "        self.w_cost = w_cost\n",
        "        self.U_mean = np.zeros(H, dtype=np.float32)\n",
        "\n",
        "    def action(self, state, plot=False, plot_best=3):\n",
        "        H, N_seq, σ, λ = self.H, self.N_seq, self.σ, self.λ\n",
        "\n",
        "        # 0) warm start / shift sequence\n",
        "        self.U_mean = np.roll(self.U_mean, -1)\n",
        "        self.U_mean[-1] = 0.0\n",
        "\n",
        "        # 1) sample candidate sequences\n",
        "        noise = np.random.normal(0.0, σ, size=(N_seq, H)).astype(np.float32)\n",
        "        U = np.clip(self.U_mean[None, :] + noise, ACT_LOW, ACT_HIGH)\n",
        "\n",
        "        # 2) evaluate candidates with GP dynamics + uncertainty-aware cost\n",
        "        J = np.zeros(N_seq, dtype=np.float64)\n",
        "        all_traj = []\n",
        "        for i in range(N_seq):\n",
        "            traj, total_cost = roll_out_trajectory(\n",
        "                s0=state,\n",
        "                Ui=U[i],\n",
        "                gamma=1.0,\n",
        "                gps=self.gps,\n",
        "                beta_var=self.beta_var,\n",
        "                include_obs_noise=self.include_obs_noise,\n",
        "                w_cost=self.w_cost\n",
        "            )\n",
        "            all_traj.append(traj)\n",
        "            J[i] = total_cost\n",
        "\n",
        "        # 3) MPPI weights (stable softmax)\n",
        "        J_min = np.min(J)\n",
        "        logits = -(J - J_min) / max(1e-8, λ)\n",
        "        w = np.exp(logits)\n",
        "        w /= np.sum(w)\n",
        "\n",
        "        # 4) update mean sequence with weighted noise (perturbations)\n",
        "        dU = w @ noise  # (H,)\n",
        "        self.U_mean = np.clip(self.U_mean + dU, ACT_LOW, ACT_HIGH)\n",
        "\n",
        "        if plot:\n",
        "            best_idx = np.argsort(J)[:plot_best]\n",
        "            best_traj = [all_traj[i] for i in best_idx]\n",
        "            plot_trajectories(state, best_traj)\n",
        "\n",
        "        return float(self.U_mean[0])\n",
        "\n",
        "# ============================================================\n",
        "# 6) Quick unit run: test rollout + MPPI closed loop\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test a single short rollout call (make sure gps is passed)\n",
        "    Ui_test = np.zeros(5, dtype=np.float32)\n",
        "    traj_test, J_test = roll_out_trajectory(\n",
        "        np.array([-0.5, 0.0], dtype=np.float32),\n",
        "        Ui_test,\n",
        "        gps=gps,\n",
        "        beta_var=0.0,                # set >0 to see risk effect\n",
        "        include_obs_noise=False      # epistemic-only variance\n",
        "    )\n",
        "    print(f\"Sanity test — rollout length={len(traj_test)}, cost={J_test:.3f}\")\n",
        "\n",
        "    # MPPI closed-loop control with learned dynamics\n",
        "    # Increase beta_var (e.g., 0.1~0.5) to make the controller more risk-averse.\n",
        "    mppi = MPPIController(\n",
        "        gps=gps,\n",
        "        H=100,\n",
        "        N_seq=60,\n",
        "        λ=0.10,\n",
        "        σ=0.7,\n",
        "        beta_var=0.2,            # risk sensitivity knob\n",
        "        include_obs_noise=False, # epistemic-only penalty\n",
        "        w_cost=None              # or pass a custom dict of weights\n",
        "    )\n",
        "\n",
        "    obs, _ = env.reset(seed=SEED)\n",
        "    traj_exec = []\n",
        "    for t in range(150):\n",
        "        a = mppi.action(obs, plot=(t == 0), plot_best=3)  # plot only at first step (optional)\n",
        "        traj_exec.append([obs.copy(), a])\n",
        "\n",
        "        obs, r, term, trunc, _ = env.step([a])  # env step for evaluation/logging\n",
        "        if (t % 1) == 0:\n",
        "            print(f\"t={t:3d}  obs={obs}  a={a:+.3f}\")\n",
        "        if term or trunc:\n",
        "            break\n",
        "\n",
        "    print(f\"Total time: {t+1} step(s)\")\n",
        "    plot_trajectory(traj_exec)\n",
        "\n",
        "    # Energy proxy\n",
        "    print(\"Energy:\", sum(a**2 for s, a in traj_exec))\n"
      ],
      "metadata": {
        "id": "G-l3-LhzH4hN"
      },
      "id": "G-l3-LhzH4hN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}